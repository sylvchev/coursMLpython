{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regression linéaire avec les moindres carrés"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "% matplotlib inline\n",
    "from __future__ import print_function\n",
    "from numpy import array, zeros, zeros_like, ones, vstack, mod, loadtxt, linspace, logspace, mean\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "from numpy.linalg import pinv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cd src/notebook/coursMLpython/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction et notations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Soit une collection de $m$ exemples $\\{x^{(i)}\\}_{i=1}^m$ dans $\\mathcal{X} \\subseteq \\mathbb{R}^n$, où $n$ est le nombre de _features_ de chaque exemple. On cherche à prédire une valeur $y^{(i)}$ de $\\mathcal{Y} \\subseteq \\mathbb{R}$ associée à chaque exemple, en se restreignant aux solutions linéaires, c'est-à-dire telle que notre hypothèse est du type $y^{(i)} = h(x^{(i)})$ avec \n",
    "\n",
    "$$h_{\\theta}(x) = \\sum_{i=0}^n \\theta_i x_i = \\theta^T X$$\n",
    "\n",
    "Ceci qui peut s'écrire :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def h(theta, x):\n",
    "    h_predit = 0.\n",
    "    for i in range(len(x)):\n",
    "        h_predit += theta[i]*x[i]\n",
    "    return h_predit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ou sous forme matricielle, plus optimisée :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def h(theta, X):\n",
    "    # print (type(theta), len(theta) )\n",
    "    return theta.dot(X) # theta'*X en matlab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vous pourrez remarquer que le produit scalaire s'écrit un peu différemment en Python et en Matlab. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La méthode des moindres carrés consiste à réduire l'erreur quadratique. Nous choisissons donc la fonction de coût suivante :\n",
    "\n",
    "$$J(\\theta) = \\frac{1}{2}\\sum_{i=1}^{m}(h_{\\theta}(x^{(i)}) - y^{(i)})^2 $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def J(theta, X, Y):\n",
    "    J = 0.\n",
    "    for i, (x_i, y_i) in enumerate(zip(X, Y)):\n",
    "        J += (h(theta, x_i) - y_i)**2\n",
    "    return 1/2.*J"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On préfèrera également la version matricielle : \n",
    "$$J(\\theta) = \\frac{1}{2m}(X^T\\theta - y)^T(X^T\\theta - y)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def J(theta, X, Y):\n",
    "    return 1/(2.*m)*(X.dot(theta) - Y).T.dot(X.dot(theta) - Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Minimisation de l'erreur par descente de gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour minimiser $J(\\theta)$, nous allons effectuer une descente de gradient, c'est-à-dire initialiser $\\theta$ puis le mettre à jour avec :\n",
    "\n",
    "$$\\theta_j := \\theta_j - \\alpha \\frac{\\partial J(\\theta)}{\\partial\\theta_j}$$\n",
    "\n",
    "La dérivée partielle de $J(\\theta)$ est équivalente à $(h_\\theta(x)-y)x_j$. On peut implémenter une version *batch* ou une version stochastique de la descente de gradient pour résoudre ce problème. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Descente de gradient en mode *batch*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La version *batch* consiste à mettre à jour la valeur de $\\theta$ avec le gradient calculé sur l'ensemble des exemples. L'algorithme s'écrit :\n",
    "\n",
    "Répéter jusqu'à convergence:\n",
    "\n",
    "$$\\theta_j := \\theta_j + \\frac{\\alpha}{m} \\sum_{i=1}^{m}(y^{(i)}-h_\\theta(x^{(i)}))x^{(i)}_j$$\n",
    "\n",
    "On peut implémenter l'algorithme *batch* de la façon suivante :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def batch_update(theta, X, Y, alpha=0.01):\n",
    "    derivative = zeros_like(theta)\n",
    "    m, n = X.shape\n",
    "    for j in range(n):\n",
    "        for i in range(m):\n",
    "            derivative[j] += alpha * (Y[i] - h(theta, X[i,:])) * X[i,j]\n",
    "    return theta + 1./m*derivative"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il est possible de réécrire cet algorithme de façon plus concise et plus efficice en utilisant une représentation matricielle :\n",
    "$$\\theta_j := \\theta_j + \\frac{\\alpha}{m} (Y-X^T\\theta) X$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def batch_update(theta, X, Y, alpha=0.01):\n",
    "    m, _ = X.shape\n",
    "    return theta + (alpha/m)* (Y-X.dot(theta)).dot(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Descente de gradient stochastique"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il est également possible d'utiliser une version stochastique de la descente de gradient. Dans ce cas l'algorithme est mis à jour après chaque exemple, ce qui accèlere considérablement la convergence. Cependant l'algorithme *batch* converge de façon certaine vers l'optimum, qui est unique et global dans notre cas, alors que la version stochastique ne permet que de s'en approcher. L'algorithme stochastique s'écrit:\n",
    "\n",
    "Répéter jusqu'à convergence:\n",
    "\n",
    "Pour $i$ de 1 à $m$:\n",
    "\n",
    "$\\theta_j := \\theta_j + \\alpha (y^{(i)} - h_\\theta (x^{(i)}) ) x^{(i)}_j $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def stochastic_update(theta, X, Y, alpha=0.01):\n",
    "    new_theta = theta.copy()\n",
    "    m = X.shape[0]\n",
    "    for i in range(m):\n",
    "        new_theta += alpha * (Y[i] - X[i,:].dot(theta)) * X[i,:]\n",
    "    return new_theta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Une version qui utilise les idiomes Python ressemblerait à :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def stochastic_update(theta, X, Y, alpha=0.01):\n",
    "    new_theta = theta.copy()\n",
    "    m = X.shape[0]\n",
    "    for i, (x_i, y_i) in enumerate(zip(X,Y)):\n",
    "        new_theta += alpha * (y_i - x_i.dot(theta)) * x_i\n",
    "    return new_theta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution explicite des moindres carrés"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il est également possible de dériver directement une solution qui minimise les moindres carrés:\n",
    "\n",
    "\\begin{equation}\n",
    "\\begin{split}\n",
    "\\nabla_\\theta J(\\theta) & = \\nabla_\\theta \\frac{1}{2}(X\\theta - y)^T(X\\theta - y)\\\\\n",
    "& = X^T X \\theta - X^T y\n",
    "\\end{split}\n",
    "\\end{equation}\n",
    "\n",
    "Pour trouver le minimum, on cherche le point om la dérivée s'annule:\n",
    "\n",
    "$$ X^T X \\theta = X^T y$$\n",
    "\n",
    "et on ferme l'équation pour obtenir la valeur de $\\theta$ qui minimise $J(\\theta)$:\n",
    "\n",
    "$$ \\theta = (X^T X)^{-1} X^T y $$\n",
    "\n",
    "Il est ainsi possible de calculer directement la valeur optimale de $\\theta$ sans avoir besoin d'itérer une descente de gradient. Par contre cette solution requiert l'inversion d'une matrice, ce qui n'est envisageable que si la taille de $X$ est raisonnable (pas plus d'un millier d'échantillon). L'algorithme est le suivant:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def normal_equation(X, Y):\n",
    "    return pinv(X.T.dot(X)).dot(X.T).dot(Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Application: estimation du prix de l'immobilier dans l'Oregon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour appliquer la régression linaire, nous allons d'abord charger un ensemble de données qui contient des informations sur les prix de 47 maisons à Portland, dans l'Oregan. Les données indiquent deux informations : \n",
    "\n",
    "* la surface de la maison en pieds carrés (ft$^2$),\n",
    "\n",
    "* le nombre de pièces\n",
    "\n",
    "Nous disposons également du prix de vente de chaque maison. Ainsi, pour ce jeu de données $m=47$ et $n=2$, nous avons donc 47 exemples $x^{(i)}$ qui sont décrits dans $\\mathbb{R}^2$ (surface et nombre de pièces) et nous essayerons de prédire le prix de la maison $y^{(i)}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = loadtxt('house_x.dat')\n",
    "Y_orig = loadtxt('house_y.dat')\n",
    "n = 2\n",
    "m = data.shape[0]\n",
    "surface_min = 500\n",
    "surface_max = 5000\n",
    "prix_min = 100\n",
    "prix_max = 800\n",
    "\n",
    "print (data[0:3, :].astype(int))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous allons pour l'instant nous concentrer uniquement sur les informations de surface : nous n'utiliserons pas le nombre de pièces pour prédire le prix des maisons. Ceci pour des raisons pédagogiques, car il est plus simple de visualiser des données unidimensionnelles. \n",
    "\n",
    "La première chose à faire est de normaliser les données de telle sorte à ce que la moyenne soit nulle et la variance unitaire."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_orig = ones(shape=(m, 2))\n",
    "X_orig[:,1] = data[:,0]\n",
    "Y = Y_orig.copy()\n",
    "\n",
    "X = ones(shape=(m, 2))\n",
    "X_mean = data[:,0].mean()\n",
    "X_std = data[:,0].std()\n",
    "X[:,1] = (data[:,0] - X_mean) / X_std\n",
    "\n",
    "Y_mean = Y.mean()\n",
    "Y_std = Y.std()\n",
    "Y = (Y - Y_mean) / Y_std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous allons définir les fonctions qui vont nous permettre de faire les affichages et les tester :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def plot_data(X, Y, color=None, label=None):\n",
    "    X_scaled = (X * X_std) + X_mean\n",
    "    Y_scaled = ((Y * Y_std) + Y_mean)/1000\n",
    "    if color is not None:\n",
    "        plt.plot(X_scaled, Y_scaled, color+'o', alpha=0.5, label=label)\n",
    "    else:\n",
    "        plt.plot(X_scaled, Y_scaled, 'ok', alpha=0.5)\n",
    "    plt.xlabel(u'surface (ft$^2$)')\n",
    "    plt.ylabel(u'Prix (k$)')\n",
    "    plt.xlim(surface_min, surface_max)\n",
    "    plt.ylim(prix_min, prix_max)\n",
    "    if label is not None:\n",
    "        plt.legend(loc='lower right')\n",
    "        \n",
    "def plot_regression(theta, color='b-', alpha=1, label=None):\n",
    "    surf_min_scaled = (surface_min-X_mean)/X_std\n",
    "    surf_max_scaled = (surface_max-X_mean)/X_std\n",
    "    regression = np.array([np.array([1, surf_min_scaled]).dot(theta), \n",
    "                           np.array([1, surf_max_scaled]).dot(theta)])\n",
    "    scaled_regression = ((regression * Y_std) + Y_mean)/1000\n",
    "    plt.plot([surface_min, surface_max], \n",
    "             scaled_regression, \n",
    "             color, alpha=alpha, label=label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_data(X[:,1], Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On applique notre algorithme *batch* avec 1000 itérations successives. Les valeurs successives des régressions sont affichées en bleu et la prédiction finale est en noir : on voit que l'algorithme converge doucement tout au long des itérations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_data(X[:,1], Y)\n",
    "theta_batch = zeros(n)\n",
    "alpha = 0.005\n",
    "iteration = 800\n",
    "J_batch = zeros(iteration)\n",
    "for i in range(iteration):\n",
    "    theta_batch = batch_update(theta_batch, X, Y, alpha)\n",
    "    J_batch[i] =  J(theta_batch, X, Y)\n",
    "    if (mod(i, iteration/10) == 0):\n",
    "        plot_regression(theta_batch, 'b-', alpha=float(i)/iteration)\n",
    "plot_regression(theta_batch, 'k-')    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On cherche maintenant à effectuer une régression linéaire avec l'algorithme stochastique. Dans ce cas, les prédictions au cours des itérations sont en rouge et la régression finale est en noir. L'algorithme converge extrêmement vite et est stabilisé après 100 itérations sur les 1000 effectuées."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_data(X[:,1], Y)\n",
    "theta_stoch = zeros(n)\n",
    "alpha = 0.005\n",
    "iteration = 800\n",
    "J_stochastic = zeros(iteration)\n",
    "for i in range(iteration):\n",
    "    theta_stoch = stochastic_update(theta_stoch, X, Y, alpha)\n",
    "    J_stochastic[i] =  J(theta_stoch, X, Y)\n",
    "    if (mod(i, iteration/10) == 0):        \n",
    "        plot_regression(theta_stoch, 'r-', alpha=float(i)/iteration)\n",
    "plot_regression(theta_stoch, 'k-')   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les algorithmes convergent à des vitesses différentes, la version stochastique étant plus rapide car en une itération $\\theta$ est mis à jour $m$ fois. Il est possible de comparer la vitesse de convergence en affichant la valeur de l'erreur quadratique $J(\\theta)$ calculée à chaque itération. On voit que l'algorithme *batch* n'a pas fini de converger après 1000 itérations alors que l'algorithme stochastique a convergé avant la 100$^e$ itération. Pour améliorer la vitesse de convergence, il est possible d'augmenter la valeur du taux d'apprentissage $\\alpha$ (*learning rate*)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f = plt.plot(J_batch, 'b', label='batch')\n",
    "g = plt.plot(J_stochastic, 'r', label='stochastic')\n",
    "plt.title('Convergence of cost function')\n",
    "plt.xlabel('iterations')\n",
    "plt.ylabel('error')\n",
    "plt.legend()    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il est également possible de calculer directement la valeur de $\\theta$ avec la solution explicite des moindres carrés. Il n'est pas nécessaire dans ce cas d'itérer l'algorithme : on obtient immédiatement la valeur optimale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_data(X[:,1], Y)\n",
    "theta_normal = normal_equation(X, Y)\n",
    "plot_regression(theta_normal, 'g-', label='Normal equation')\n",
    "plt.title('Regression with Normal Equation')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparons maintenant les valeurs des regressions obtenues avec les 3 méthodes : la descente de gradient *batch* (bleu), la descente de gradient stochastique (rouge) et la solution explicite des moindres carrés (vert). On peut voir que la solution explicite et la méthode stochastique ont convergé vers le même optimum. La méthode *batch* n'a pas réussi à atteindre l'optimum après 1000 itérations: il faut soit augmenter le nombre d'itérations soit choisir un taux d'apprentissage $\\alpha$ plus grand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_data(X[:,1], Y)\n",
    "plot_regression(theta_batch, 'b-', label=r'Batch: $J(\\theta)=$ %g' % J(theta_batch, X, Y))\n",
    "plot_regression(theta_stoch, 'r-', label=r'Stochastic: $J(\\theta)=$%g' % J(theta_stoch, X, Y))  \n",
    "plot_regression(theta_normal, 'g-', label=r'Normal eq.: $J(\\theta)=$%g' % J(theta_normal, X, Y))\n",
    "plt.title('gradient-based algorithms vs Normal equation')   \n",
    "plt.legend(loc='lower right')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour choisir correctement le taux d'apprentissage, il faut faire des tests. En pratique, soit $\\alpha$ est suffisamment petit et l'algorithme va converger, soit $\\alpha$ est trop grand et l'algorithme va rapidement diverger. Une façon simple est de vérifier la valeur de l'erreur quadratique $J(\\theta)$ après quelques itérations pour différentes valeurs de $\\alpha$, et d'affiner itérativement son choix.\n",
    "\n",
    "Sur le graphique ci dessous, on peut voir que la vitesse de convergence de l'algorithme s'accroit jusqu'à $\\alpha=0.5$ où elle atteint un plateau. Au delà de $\\alpha=2$, l'algorithme commence à diverger: les valeurs de $J(\\theta)$ pour $\\alpha > 2$ ne sont pas représentées car elles sont très grandes (supérieure à $10^9$), voire dépassent la précision machine (aboutissant à  des NaN)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "iterations = 10\n",
    "alpha = logspace(-5, 1, 100)\n",
    "J_conv = np.zeros(len(alpha))\n",
    "for i, a in enumerate(alpha):\n",
    "    theta = zeros(n)\n",
    "    for t in range(iterations):\n",
    "        theta = batch_update(theta, X, Y, a)\n",
    "    J_conv[i] = J(theta, X, Y)\n",
    "plt.figure()\n",
    "plt.plot(alpha[:88], J_conv[:88]) \n",
    "plt.xlabel(r'$\\alpha$')\n",
    "plt.ylabel(r'$J(\\theta)$')\n",
    "plt.title(u'Estimation de la convergence après 10 itérations')\n",
    "plt.xscale('log')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualisation de la descente du gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous allons maintenant voir la forme du gradient. Pour cela, nous allons calculer la valeur de $J(\\theta)$ pour différents $\\theta$ et afficher le résultat. Les valeurs de $\\theta_0$ sont en abscisse et les valeurs de $\\theta_1$ en ordonnée, le plan est coloré en fonction de la valeur de $J(\\theta)$. Comme $J(\\theta)$ est l'erreur quadratique, il y a un minimum global, qui est indiqué par un point en noir, c'est la valeur trouvée par notre descente de gradient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "theta0_vals = linspace(-1, 1, 100)\n",
    "theta1_vals = linspace(-0.1, 1.4, 100)\n",
    "J_vals = zeros(shape=(theta0_vals.size, theta1_vals.size))\n",
    "for t1, theta0 in enumerate(theta0_vals):\n",
    "    for t2, theta1 in enumerate(theta1_vals):\n",
    "        J_vals[t1, t2] = J(array([theta0, theta1]), X, Y)\n",
    "J_vals = J_vals.T\n",
    "\n",
    "def plot_gradient(theta0_vals, theta1_vals, Z):\n",
    "    levels = logspace(2, 8, 40)\n",
    "    plt.set_cmap(cm.hsv)\n",
    "    plt.contourf(theta0_vals, theta1_vals, Z, 40)\n",
    "    cbar = plt.colorbar()\n",
    "    cbar.set_label(r'$J(\\theta)$')\n",
    "    v = plt.axis()\n",
    "    plt.contour(theta0_vals, theta1_vals, Z, 40, hold=True, colors='k')\n",
    "    plt.xlabel(r'$\\theta_0$')\n",
    "    plt.ylabel(r'$\\theta_1$')\n",
    "\n",
    "plot_gradient(theta0_vals, theta1_vals, J_vals)\n",
    "plt.scatter(theta_stoch[0], theta_stoch[1], c='k')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il est possible de visualiser la descente de gradient en affichant le point de démarrage de l'algorithme $\\theta = (0,0)$ avec un point noir et de tracer les points qui indiquent les valeurs prises successivement par $\\theta$ au fur et à mesure des itérations. Regardons comment l'algorithme de descente de gradient *batch* converge:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_gradient(theta0_vals, theta1_vals, J_vals)\n",
    "\n",
    "alpha = 0.1\n",
    "iteration = 1000\n",
    "t_batch = zeros(shape=(iteration, 2))\n",
    "for i in range(iteration):\n",
    "    t_batch[i,:] = batch_update(t_batch[i-1,:], X, Y, alpha)\n",
    "plt.plot([0, 0], t_batch[-1,:], c='k')\n",
    "plt.plot(t_batch[:,0], t_batch[:,1], 'xk')\n",
    "plt.scatter(0, 0, c='k')\n",
    "plt.scatter(t_batch[-1,0], t_batch[-1,1], c='k')\n",
    "plt.title('convergence of the batch gradient')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparons maintenant avec l'algorithme de descente de gradient stochastique. On voit que la convergence est beaucoup plus rapide : le gradient \"saute\" beaucoup plus vite vers le centre bien que la valeur de $\\alpha$ soit identique en *batch* et en stochastique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_gradient(theta0_vals, theta1_vals, J_vals)\n",
    "\n",
    "alpha = 0.01\n",
    "iteration = 1000\n",
    "t_stoch = zeros(shape=(iteration, 2))\n",
    "for i in range(iteration):\n",
    "    t_stoch[i,:] = stochastic_update(t_stoch[i-1,:], X, Y, alpha)\n",
    "plt.plot([0, 0], t_batch[-1,:], c='k')\n",
    "plt.plot(t_stoch[:,0], t_stoch[:,1], 'xk')\n",
    "plt.scatter(0, 0, c='k')\n",
    "plt.scatter(t_stoch[-1,0], t_stoch[-1,1], c='k')\n",
    "plt.title('convergence of the stochastic gradient')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Un maximum d'efficacité avec scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il n'est pas nécessaire de réinventer la roue, tous les algorithmes que nous avons vu ont été implémentés et vérifiés par une large communauté de programmeurs. C'est même la devise de Python, \"Batteries included\", car il y a des bibliothèques pour tous les problèmes possibles.\n",
    "\n",
    "Nous allons regarder comment utiliser ces algorithmes avec la bibliothèque scikit-learn (appelée sklearn). Commençons par la régression en utilisant la solution explicite des moindres carrés.\n",
    "\n",
    "Nous allons utiliser le StandardScaler qui permet de centrer les données et LinearRegression pour calculer la regression linéaire."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn import linear_model, preprocessing\n",
    "\n",
    "data = loadtxt('house_x.dat')\n",
    "Y_orig = loadtxt('house_y.dat')\n",
    "\n",
    "# Scaling data\n",
    "Xscaler = preprocessing.StandardScaler().fit(data[:,0])\n",
    "X = np.atleast_2d(Xscaler.transform(data[:,0]))\n",
    "Yscaler = preprocessing.StandardScaler().fit(Y_orig)\n",
    "Y = Yscaler.transform(Y_orig)\n",
    "\n",
    "# regression with Normal equation\n",
    "regression = linear_model.LinearRegression(fit_intercept=True).fit(X.T, Y) #(data, Y_orig)\n",
    "\n",
    "scatter(Xscaler.inverse_transform(X).T, Yscaler.inverse_transform(Y), c='black')\n",
    "plot(Xscaler.inverse_transform(X).T, Yscaler.inverse_transform(regression.predict(X.T)), \n",
    "     color='green', label=\"Regression error: %.2f\" % mean((regression.predict(X.T) - Y) ** 2))\n",
    "plt.title('Regression with Normal Equation')\n",
    "plt.legend(loc='lower right')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scikit-learn propose une implémentation efficace de la descente de gradient stochastique:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDRegressor\n",
    "\n",
    "stochastic_descent = SGDRegressor(alpha=0.01, n_iter=100).fit(X.T, Y)\n",
    "\n",
    "scatter(Xscaler.inverse_transform(X).T, Yscaler.inverse_transform(Y), c='black')\n",
    "plot(Xscaler.inverse_transform(X).T, Yscaler.inverse_transform(stochastic_descent.predict(X.T)), \n",
    "     color='red', label=\"Regression error: %.2f\" % mean((stochastic_descent.predict(X.T) - Y) ** 2))\n",
    "plt.title('Regression with SGD')\n",
    "plt.legend(loc='lower right')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La bibliothèque scikit-learn propose des implémentations performantes et faciles à utiliser des principaux algorithmes d'apprentissage automatique. Il est ainsi possible d'appliquer des normalisations et des traitements usuels sur les données en quelques lignes de calculs. Du point de vue performance, scikit-learn propose quand c'est possible des implémentations multiprocessus."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
